---
title: 'Photo-Human Entanglement'
date: '2022-12-08'
tags: []
excerpt: ''
isPublished: true
---

Things and humans are one and the same, they are inseparable and cannot exist without the other. This is the thesis of posthumanist theories. 

In this short post I will examine the Memory feature in iOS’s Photo app through the posthumanist perspective and explain how tools and us become entangled as one. To distinguish “memory” used in everyday language, I will capitalize “Memory” while referring to the computer-generated album.

Memory is a feature embedded in the Photo app where we store all our photos. It uses a local Machine Learning algorithm to analyze the content of our photos and curate relevant ones into a slideshow based on locations, times, and themes.  

The first step starts with us taking photos with the camera, inputing them into the photo library, based on which the ML algorithm will work its magic. One might say a photo is an unbiased, objective record of the reality. The truth is far from that. The object we choose to record, the specific angle we point our camera to, and the moment we press the shutter, are intentional or unintentional decisions made against many other alternatives. On top of that there’re filters, which allow us to apply stylistic modifications to photos. As a result, when we input the data, we already went through a selective process of including what kinds of things we wanted to record and how they are recorded.  

After running in the background analyzing our photos, the Photo app then uses push notification of the system to inform us that “a new memory is ready”. These Memories have two effects. 

First, by using algorithmic intelligence to group photos in certain themes, they reveal connections among events formerly unnoticed. For example, currently there’s a Memory in my phone called “Snow Days over the Years”. As the title suggests, it collocates photos with snowy scenes taken in different times and locations. In the process of reviewing these photos, I become aware of the common property (“snowy”) shared by these events as highlighted by the app. I make a new link between otherwise disconnected time and space.

Secondly, by surfacing old photos, these Memories reinforce our memory of related events. For example, when I look at a specific type of Memories called “x years ago”, I was shown photos taken on the same date in previous years and reminded what happened. It brushes up my otherwise long sealed memory. However, what’s more concerning is that the feature also plays a critical role in deciding the memory of which events will be reinforced. Among thousands of photos, only the ones that are curated into Memories will be pushed to users for review, leaving a majority of others in the dark. That is to say, when the Memory feature privileges showing certain photos over others, it is in fact making a value judgement of what kinds of things are worth remembering.

The final step is the most important mechanism that is the natural temporal process of forgetting, with which Memory completes its journey and virtually becomes our memory. Consider the moment when we just finish taking photos and still remember what we see in person, we are well aware of the difference between photos and the reality. Photos are partial capture of what we see, a copy of reality at best. 

However, as time goes by, we start to forget things, losing the details of what happened exactly. Things start to fade—the weather of the day, the color of the flowers, or the face of a nice stranger. The Memory feature was thought to be a solution. Every time it prompts us with photos, we revisit the past and recollect some of the details—but let us not forget these photos are not only parts of the reality, but also a selective and even modified ones. As a result, every time we revisit the photos, we are in effect moving a little bit away from what it was that we saw and replacing it instead with what we recorded. 

Let’s say I took a photo of the cherry blossom at [the quad](https://en.wikipedia.org/wiki/University_of_Washington_Quad) and retouched it to look more saturated—more pink, so as more instagrammable. At the time I knew the photo was not what the flower actually looked like, but decades from now through the process of forgetting and revisiting, I will only come to take the photo as reality. All I can recall is what the photo tells me—the cherry blossom has always been that pink. The photo *is* my memory. 

Now I’d like to conclude with a touch of theory. In the case study above, I’ve demonstrated how humans and tools are entangled as one hybrid actor-network. The configuration starts with human inputting data that enables the very existence of the Memory feature, and then through the ML algorithm Memory alters, reinforces, and finally becomes our own memory. Our actions of stocking photos bring about Memory, which then constitutes what we remember and know about our past—an essential component of our identities. Thus, in an intricate intertwining a new reality is enacted through these intra-actions between Memory and us. Both humans and tools emerge in this whole of relational being and would not exist without the other.

No wonder we feel sad when we lose our photos, because we are, after all, losing a part of ourselves.